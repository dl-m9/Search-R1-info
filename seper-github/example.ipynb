{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Model\n",
    "Load the generation model and entailment judge model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /Qwen/Qwen3-8B/resolve/main/tokenizer_config.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7ff646643640>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\"), '(Request ID: 5b0c80f4-8926-410e-bcb6-27f18ff5a907)')' thrown while requesting HEAD https://huggingface.co/Qwen/Qwen3-8B/resolve/main/tokenizer_config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /Qwen/Qwen3-8B/resolve/main/tokenizer_config.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7ff6466431f0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\"), '(Request ID: b26f2a3c-fccd-4977-b8b9-2a65f8fed8db)')' thrown while requesting HEAD https://huggingface.co/Qwen/Qwen3-8B/resolve/main/tokenizer_config.json\n",
      "Retrying in 2s [Retry 2/5].\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Build generator\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m generator \u001b[38;5;241m=\u001b[39m \u001b[43mHuggingfaceModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdefault\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_implementation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mflash_attention_2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m generator\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Build entailment model\u001b[39;00m\n",
      "File \u001b[0;32m/forest/forest/Search-R1-info/seper/models/huggingface_models.py:250\u001b[0m, in \u001b[0;36mHuggingfaceModel.__init__\u001b[0;34m(self, model_name, stop_sequences, max_new_tokens, device, **kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqwen\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_name\u001b[38;5;241m.\u001b[39mlower():\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;66;03m# Qwen model support\u001b[39;00m\n\u001b[1;32m    248\u001b[0m     model_id \u001b[38;5;241m=\u001b[39m model_name\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    257\u001b[0m         model_id,\n\u001b[1;32m    258\u001b[0m         trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    259\u001b[0m         device_map\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    261\u001b[0m     )\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/searchr1/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py:858\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    857\u001b[0m \u001b[38;5;66;03m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[39;00m\n\u001b[0;32m--> 858\u001b[0m tokenizer_config \u001b[38;5;241m=\u001b[39m \u001b[43mget_tokenizer_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tokenizer_config:\n\u001b[1;32m    860\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tokenizer_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/envs/searchr1/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py:690\u001b[0m, in \u001b[0;36mget_tokenizer_config\u001b[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m     token \u001b[38;5;241m=\u001b[39m use_auth_token\n\u001b[1;32m    689\u001b[0m commit_hash \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 690\u001b[0m resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mTOKENIZER_CONFIG_FILE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    707\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate the tokenizer configuration file, will try to use the model config instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/searchr1/lib/python3.9/site-packages/transformers/utils/hub.py:403\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 403\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    418\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m _get_cache_file_to_return(path_or_repo_id, full_filename, cache_dir, revision)\n",
      "File \u001b[0;32m/opt/conda/envs/searchr1/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/searchr1/lib/python3.9/site-packages/huggingface_hub/file_download.py:1007\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m    989\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1004\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m   1005\u001b[0m     )\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1007\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m   1016\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/searchr1/lib/python3.9/site-packages/huggingface_hub/file_download.py:1070\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pointer_path\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;66;03m# Try to get metadata (etag, commit_hash, url, size) from the server.\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;66;03m# If we can't, a HEAD request error is returned.\u001b[39;00m\n\u001b[0;32m-> 1070\u001b[0m (url_to_download, etag, commit_hash, expected_size, xet_file_data, head_call_error) \u001b[38;5;241m=\u001b[39m \u001b[43m_get_metadata_or_catch_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1073\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrelative_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;66;03m# etag can be None for several reasons:\u001b[39;00m\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;66;03m# 1. we passed local_files_only.\u001b[39;00m\n\u001b[1;32m   1087\u001b[0m \u001b[38;5;66;03m# 2. we don't have a connection\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;66;03m# If the specified revision is a commit hash, look inside \"snapshots\".\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;66;03m# If the specified revision is a branch or tag, look inside \"refs\".\u001b[39;00m\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head_call_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1096\u001b[0m     \u001b[38;5;66;03m# Couldn't make a HEAD call => let's try to find a local file\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/searchr1/lib/python3.9/site-packages/huggingface_hub/file_download.py:1543\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1542\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1543\u001b[0m         metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\n\u001b[1;32m   1545\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1546\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[1;32m   1547\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m storage_folder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m relative_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1548\u001b[0m             \u001b[38;5;66;03m# Cache the non-existence of the file\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/searchr1/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/searchr1/lib/python3.9/site-packages/huggingface_hub/file_download.py:1460\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers, endpoint)\u001b[0m\n\u001b[1;32m   1457\u001b[0m hf_headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccept-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midentity\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# prevent any compression => we want to know the real size of the file\u001b[39;00m\n\u001b[1;32m   1459\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1460\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1465\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1466\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1467\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1468\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1469\u001b[0m hf_raise_for_status(r)\n\u001b[1;32m   1471\u001b[0m \u001b[38;5;66;03m# Return\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/searchr1/lib/python3.9/site-packages/huggingface_hub/file_download.py:283\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;66;03m# Recursively follow relative redirects\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 283\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m300\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m399\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/envs/searchr1/lib/python3.9/site-packages/huggingface_hub/file_download.py:306\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[1;32m    305\u001b[0m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[0;32m--> 306\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mhttp_backoff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m hf_raise_for_status(response)\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/envs/searchr1/lib/python3.9/site-packages/huggingface_hub/utils/_http.py:329\u001b[0m, in \u001b[0;36mhttp_backoff\u001b[0;34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;66;03m# Sleep for X seconds\u001b[39;00m\n\u001b[1;32m    328\u001b[0m logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msleep_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms [Retry \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnb_tries\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_retries\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m].\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 329\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43msleep_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# Update sleep time for next retry\u001b[39;00m\n\u001b[1;32m    332\u001b[0m sleep_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(max_wait_time, sleep_time \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import os\n",
    "# os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "from seper.calculate import gen_answers_batch, calculate_uncertainty_soft_batch, create_collate_fn\n",
    "from seper.models.huggingface_models import HuggingfaceModel\n",
    "from seper.uncertainty_measures.semantic_entropy import EntailmentDeberta\n",
    "from seper.calculate import process_item_for_seper\n",
    "export http_proxy=http://192.168.32.28:18000 && export https_proxy=http://192.168.32.28:18000\n",
    "\n",
    "model_path = 'Qwen/Qwen3-8B'\n",
    "num_generations = 10 # 10 is good for most cases\n",
    "sub_batch_size = 10\n",
    "temperature = 1.0\n",
    "max_new_tokens = 128\n",
    "max_context_words = 4096\n",
    "computation_chunk_size = 8 # adjust to balance speeds and gpu memory cost\n",
    "prompt_type = 'default'\n",
    "device = 'cuda:1'\n",
    "\n",
    "# Build generator\n",
    "generator = HuggingfaceModel(\n",
    "    model_path,\n",
    "    stop_sequences='default',\n",
    "    max_new_tokens=max_new_tokens,\n",
    "    torch_dtype=torch.float16,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    device=device,\n",
    ")\n",
    "generator.model.eval()\n",
    "\n",
    "# Build entailment model\n",
    "entailment_model = EntailmentDeberta(device=device)\n",
    "entailment_model.model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Sampling\n",
    "Generate for `num_generations` times and collect the results and probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example={\n",
    "    'question' : \"In what city was the band behind the album Love Bites formed?\",\n",
    "    'context'  : \"\"\"Doc 1(Title: \"Love Bites (band)\") Love Bites (band) Love Bites is an English girl band that formed in 2004 and disbanded in 2007, but reformed again in 2011. The band, named after a Def Leppard song, formed while the members were still in school. They started out as a three piece group consisting of Danielle Graham, Aimee Haddon and Hannah Haddon with Nicki Wood later joining the band. They did some touring and recording. In 2006 Wood left the band and was replaced by Beka Pritchard. They broke up the next year. The band released their debut single, \"You Broke My Heart\", on October 2005.\n",
    "Doc 2(Title: \"Lovebites (band)\") Lovebites (band) Lovebites (stylized as LOVEBITES) is a Japanese all-female heavy metal band, formed in 2016 by former Destrose members Miho and Haruna. They derived their name from the song \"Love Bites (So Do I)\" by Halestorm. Lovebites was formed in Tokyo in 2016 by bassist Miho and drummer Haruna. The two met while members of Destrose, another all-female metal band that disbanded in 2015. After recruiting guitarist Midori and support guitarist and keyboardist Miyako (then known as Mi-Ya), the four chose vocalist Asami based on a demo she made. Midori was in the band Gekijo Metalicche, Miyako was a\n",
    "Doc 3(Title: \"Love Bites (album)\") their particular brand of pop and their disillusionment with its restrictions. Producer Martin Rushent clarifies the elements of the sound even further, and Shelley's songwriting continues to improve\"\". In a retrospective review, BBC Music described it as \"\"an essential purchase for anyone remotely interested in punk's history.\"\" AllMusic wrote: \"\"More musically accomplished, more obsessively self-questioning, and with equally energetic yet sometimes gloomy performances, \"\"Love Bites\"\" finds the Buzzcocks coming into their own.\"\" Love Bites (album) Love Bites is the second studio album by English punk rock band Buzzcocks. It was released on 22 September 1978, through United Artists, on which album is the band behind the album Love Bites formed?\n",
    "Doc 1(Title: Buzzcocks) Buzzcocks Buzzcocks are an English punk rock band, formed in Bolton, England, in 1976 by singer-songwriter-guitarist Pete Shelley and singer-songwriter Howard Devoto. They are regarded as a seminal influence on the Manchester music scene, the independent record label movement, punk rock, power pop, and pop punk. They achieved commercial success with singles that fused pop craftsmanship with rapid-fire punk energy. These singles were collected on \"\"Singles Going Steady\"\", described by critic Ned Raggett as a \"\"punk masterpiece\"\". Devoto and Shelley chose the name \"\"Buzzcocks\"\" after reading the headline, \"\"It's the Buzz, Cock!\"\", in a review of the TV series \"\"Rock\n",
    "Doc 2(Title: Buzzcocks) Buzzcocks Buzzcocks are an English punk rock band, formed in Bolton, England, in 1976 by singer-songwriter-guitarist Pete Shelley and singer-songwriter Howard Devoto. They are regarded as a seminal influence on the Manchester music scene, the independent record label movement, punk rock, power pop, and pop punk. They achieved commercial success with singles that fused pop craftsmanship with rapid-fire punk energy. These singles were collected on \"\"Singles Going Steady\"\", described by critic Ned Raggett as a \"\"punk masterpiece\"\". Devoto and Shelley chose the name \"\"Buzzcocks\"\" after reading the headline, \"\"It's the Buzz, Cock!\"\", in a review of the TV series \"\"Rock\n",
    "Doc 3(Title: Buzzcocks) the Institute, responded to the notice. Trafford had previously been involved in electronic music, while McNeish had played rock. By late 1975, Trafford and McNeish had recruited a drummer and formed, in effect, an embryonic version of Buzzcocks. The band formed, officially, in February 1976; McNeish assumed the stage name Pete Shelley and Trafford named himself Howard Devoto. They performed live for the first time on 1 April 1976 at their college. Garth Davies played bass guitar and Mick Singleton played drums. Singleton also played in local band Black Cat Bone. After reading an \"\"NME\"\" review of the Sex Pistols'\"\"\",\n",
    "    'answers' : ['Bolton'] # this is the provided ground-truth answers\n",
    "}\n",
    "result = gen_answers_batch(example, \n",
    "                           generator, \n",
    "                           temperature, \n",
    "                           num_generations, \n",
    "                           sub_batch_size, \n",
    "                           max_new_tokens, \n",
    "                           prompt_type, \n",
    "                           device,\n",
    "                           max_context_words)\n",
    "\n",
    "# Baseline example with empty context\n",
    "example_baseline = example.copy()\n",
    "example_baseline['context'] = ''\n",
    "\n",
    "result_baseline = gen_answers_batch(\n",
    "    example_baseline,\n",
    "    generator,\n",
    "    temperature,\n",
    "    num_generations,\n",
    "    sub_batch_size,\n",
    "    max_new_tokens,\n",
    "    prompt_type,\n",
    "    device,\n",
    "    max_context_words\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Is Elon Musk older than Sam Altman?',\n",
       " 'context': 'Elon Musk was born on June 28, 1971. Sam Altman was born on April 22, 1985.',\n",
       " 'answers': ['Yes'],\n",
       " 'responses': [('Yes. Elon Musk was born 9 years before Sam Altman.',\n",
       "   [-0.011683372780680656,\n",
       "    -0.22827866673469543,\n",
       "    -1.8856996297836304,\n",
       "    -1.0728830375228426e-06,\n",
       "    -1.9192511899746023e-05,\n",
       "    -3.814689989667386e-06,\n",
       "    -1.063927412033081,\n",
       "    -1.3947389561508317e-05,\n",
       "    -1.4852174520492554,\n",
       "    -0.06590946763753891,\n",
       "    -0.000164018536452204,\n",
       "    -0.011408685706555843,\n",
       "    -0.00011860620725201443,\n",
       "    -4.851700214203447e-05,\n",
       "    -3.814689989667386e-06,\n",
       "    -0.0003120412293355912]),\n",
       "  ('Yes.', [-0.011683372780680656, -0.22827866673469543]),\n",
       "  ('Yes. Elon Musk was born in 1971, while Sam Altman was born in 1985, making Elon Musk older than Sam Altman.',\n",
       "   [-0.011683372780680656,\n",
       "    -0.22827866673469543,\n",
       "    -1.8856996297836304,\n",
       "    -1.0728830375228426e-06,\n",
       "    -1.9192511899746023e-05,\n",
       "    -3.814689989667386e-06,\n",
       "    -1.063927412033081,\n",
       "    -1.3947389561508317e-05,\n",
       "    -0.360217422246933,\n",
       "    -5.9126061387360096e-05,\n",
       "    -3.576278118089249e-07,\n",
       "    -5.960462772236497e-07,\n",
       "    -4.410734163684538e-06,\n",
       "    -2.50339189733495e-06,\n",
       "    -0.06272532045841217,\n",
       "    -0.9067647457122803,\n",
       "    -0.00028701478731818497,\n",
       "    -9.679325739853084e-05,\n",
       "    -6.198863957251888e-06,\n",
       "    -3.576272320060525e-06,\n",
       "    -1.4305012882687151e-05,\n",
       "    -3.4570634852570947e-06,\n",
       "    -1.5497195136049413e-06,\n",
       "    -5.960462772236497e-07,\n",
       "    -1.7881377516459906e-06,\n",
       "    -8.940656698541716e-06,\n",
       "    -1.0728830375228426e-06,\n",
       "    -0.010400382801890373,\n",
       "    -0.009456484578549862,\n",
       "    -0.027622122317552567,\n",
       "    -8.344646857949556e-07,\n",
       "    -9.775113539944869e-06,\n",
       "    -1.6689286894688848e-06,\n",
       "    -0.05547184869647026,\n",
       "    -0.045442916452884674,\n",
       "    -1.3947389561508317e-05,\n",
       "    -5.245071224635467e-05,\n",
       "    -4.887569048150908e-06,\n",
       "    -0.8436543941497803]),\n",
       "  ('Yes.', [-0.011683372780680656, -0.22827866673469543]),\n",
       "  ('Yes, Elon Musk is older than Sam Altman.',\n",
       "   [-0.011683372780680656,\n",
       "    -2.587653636932373,\n",
       "    -0.00042906138696707785,\n",
       "    -7.152555099310121e-07,\n",
       "    -1.156323378381785e-05,\n",
       "    -1.9073468138230965e-06,\n",
       "    -0.00488303042948246,\n",
       "    -0.03279867395758629,\n",
       "    -8.583032467868179e-06,\n",
       "    -3.814689989667386e-06,\n",
       "    -4.708655978902243e-05,\n",
       "    -1.1086402082582936e-05,\n",
       "    -0.23797284066677094]),\n",
       "  ('Yes.', [-0.011683372780680656, -0.22827866673469543]),\n",
       "  ('Yes.', [-0.011683372780680656, -0.22827866673469543]),\n",
       "  ('Yes, Elon Musk is older than Sam Altman. Elon Musk was born in 1971, while Sam Altman was born in 1985, making Elon Musk approximately 14 years older than Sam Altman.',\n",
       "   [-0.011683372780680656,\n",
       "    -2.587653636932373,\n",
       "    -0.00042906138696707785,\n",
       "    -7.152555099310121e-07,\n",
       "    -1.156323378381785e-05,\n",
       "    -1.9073468138230965e-06,\n",
       "    -0.00488303042948246,\n",
       "    -0.03279867395758629,\n",
       "    -8.583032467868179e-06,\n",
       "    -3.814689989667386e-06,\n",
       "    -4.708655978902243e-05,\n",
       "    -1.1086402082582936e-05,\n",
       "    -0.23797284066677094,\n",
       "    -1.3036227226257324,\n",
       "    -3.3378546504536644e-06,\n",
       "    -0.0005138983833603561,\n",
       "    -2.50339189733495e-06,\n",
       "    -0.04642118141055107,\n",
       "    -1.2278481335670222e-05,\n",
       "    -0.07208003848791122,\n",
       "    -1.5258672647178173e-05,\n",
       "    -1.1920928244535389e-07,\n",
       "    -4.768370445162873e-07,\n",
       "    -2.264974000354414e-06,\n",
       "    -1.1920922133867862e-06,\n",
       "    -0.018714407458901405,\n",
       "    -0.49933135509490967,\n",
       "    -0.00010680581908673048,\n",
       "    -7.164221460698172e-05,\n",
       "    -1.966933996300213e-05,\n",
       "    -1.311301275563892e-06,\n",
       "    -1.1801649634435307e-05,\n",
       "    -8.344646857949556e-07,\n",
       "    -4.768370445162873e-07,\n",
       "    -3.576278118089249e-07,\n",
       "    -1.7881377516459906e-06,\n",
       "    -5.006777428206988e-06,\n",
       "    -5.960462772236497e-07,\n",
       "    -0.030721720308065414,\n",
       "    -0.027909433469176292,\n",
       "    -0.038173723965883255,\n",
       "    -8.344646857949556e-07,\n",
       "    -1.7881233361549675e-05,\n",
       "    -8.344646857949556e-07,\n",
       "    -2.0343210697174072,\n",
       "    -1.5139465176616795e-05,\n",
       "    -4.51792984677013e-05,\n",
       "    -9.858122211880982e-05,\n",
       "    -8.106198947643861e-06,\n",
       "    -3.802703940891661e-05,\n",
       "    -8.797258487902582e-05,\n",
       "    -3.6954811548639555e-06,\n",
       "    -3.3378044463461265e-05,\n",
       "    -1.9073468138230965e-06,\n",
       "    -6.437094270950183e-05]),\n",
       "  ('Yes, Elon Musk is older than Sam Altman.',\n",
       "   [-0.011683372780680656,\n",
       "    -2.587653636932373,\n",
       "    -0.00042906138696707785,\n",
       "    -7.152555099310121e-07,\n",
       "    -1.156323378381785e-05,\n",
       "    -1.9073468138230965e-06,\n",
       "    -0.00488303042948246,\n",
       "    -0.03279867395758629,\n",
       "    -8.583032467868179e-06,\n",
       "    -3.814689989667386e-06,\n",
       "    -4.708655978902243e-05,\n",
       "    -1.1086402082582936e-05,\n",
       "    -0.23797284066677094]),\n",
       "  ('Yes. Elon Musk is born in 1971, and Sam Altman is born in 1985, hence Elon Musk is older than Sam Altman by 14 years.',\n",
       "   [-0.011683372780680656,\n",
       "    -0.22827866673469543,\n",
       "    -1.8856996297836304,\n",
       "    -1.0728830375228426e-06,\n",
       "    -1.9192511899746023e-05,\n",
       "    -3.814689989667386e-06,\n",
       "    -0.4233023524284363,\n",
       "    -0.7766733169555664,\n",
       "    -0.6058681011199951,\n",
       "    -0.003873941022902727,\n",
       "    -1.0013530300057027e-05,\n",
       "    -9.536738616588991e-07,\n",
       "    -6.198863957251888e-06,\n",
       "    -8.702239938429557e-06,\n",
       "    -0.302765429019928,\n",
       "    -0.9597368836402893,\n",
       "    -0.0024404525756835938,\n",
       "    -0.0013381821336224675,\n",
       "    -7.748573807475623e-06,\n",
       "    -0.07657434791326523,\n",
       "    -0.00015555603022221476,\n",
       "    -0.0002236116270069033,\n",
       "    -4.362964682513848e-05,\n",
       "    -7.867782187531702e-06,\n",
       "    -8.106198947643861e-06,\n",
       "    -0.00013469743134919554,\n",
       "    -3.266281055402942e-05,\n",
       "    -0.025196164846420288,\n",
       "    -3.6338279247283936,\n",
       "    -0.08740188181400299,\n",
       "    -1.156323378381785e-05,\n",
       "    -0.0006972504197619855,\n",
       "    -5.722029527532868e-06,\n",
       "    -4.887569048150908e-06,\n",
       "    -0.007375511806458235,\n",
       "    -0.001190906623378396,\n",
       "    -5.590759246842936e-05,\n",
       "    -0.00028165188268758357,\n",
       "    -1.811964830267243e-05,\n",
       "    -1.7144793272018433,\n",
       "    -0.14313068985939026,\n",
       "    -0.002284300047904253,\n",
       "    -0.00034421717282384634,\n",
       "    -7.73638384998776e-05,\n",
       "    -0.002534988336265087])]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Calculate Î”SePer\n",
    "Aggregate semantic-equivalent answers and compute belief shift on gt answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['question', 'response_text', 'answers', 'likelihood', 'context_label', 'log_liks_agg', 'context']\n",
    "seper_collate_fn = create_collate_fn(keys)\n",
    "\n",
    "# calculate seper\n",
    "with torch.no_grad():\n",
    "    # Convert for SEPER\n",
    "    r = process_item_for_seper(result)\n",
    "    rb = process_item_for_seper(result_baseline)\n",
    "    seper_input = seper_collate_fn([r, rb])\n",
    "    seper, seper_baseline = calculate_uncertainty_soft_batch(\n",
    "        seper_input, entailment_model, computation_chunk_size\n",
    "    )\n",
    "    d_seper = seper - seper_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extented Results: Fine-grained Retrieval Utility Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_baseline={\n",
    "    'question': 'Is Elon Musk older than Sam Altman?',\n",
    "    'context': '',\n",
    "    'answers': ['Yes'], # this is the provided ground-truth answers\n",
    "}\n",
    "\n",
    "example_piece1 = example_baseline.copy()\n",
    "example_piece1['context'] = 'Elon Musk was born on June 28, 1971.'\n",
    "example_piece2 = example_baseline.copy()\n",
    "example_piece2['context'] = 'Sam Altman was born on April 22, 1985.'\n",
    "\n",
    "result_piece1 = gen_answers_batch(example_piece1, generator, temperature, num_generations, sub_batch_size, max_new_tokens, prompt_type, device, max_context_words)\n",
    "result_piece2 = gen_answers_batch(example_piece2, generator, temperature, num_generations, sub_batch_size, max_new_tokens, prompt_type, device, max_context_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Baseline) SePer without retrieved information: 0.5311136874747243\n",
      " SePer with two pieces of information: 0.9920210827879619, Î”SePer: 0.46090739531323754\n",
      " SePer with one piece of information: 0.6686031010404139, Î”SePer: 0.13748941356568956\n",
      " SePer with another piece of information: 0.8733925752846344, Î”SePer: 0.3422788878099101\n"
     ]
    }
   ],
   "source": [
    "# calculate seper\n",
    "with torch.no_grad():\n",
    "    # Convert for SEPER\n",
    "    r_1 = process_item_for_seper(result_piece1)\n",
    "    r_2 = process_item_for_seper(result_piece2)\n",
    "    seper_input = seper_collate_fn([r_1, r_2])\n",
    "    seper_piece1, seper_piece2 = calculate_uncertainty_soft_batch(\n",
    "        seper_input, entailment_model, computation_chunk_size\n",
    "    )\n",
    "    d_seper_piece1 = seper_piece1 - seper_baseline\n",
    "    d_seper_piece2 = seper_piece2 - seper_baseline\n",
    "\n",
    "print(\n",
    "    f'(Baseline) SePer without retrieved information: {seper_baseline}\\n', \n",
    "    f'SePer with two pieces of information: {seper}, Î”SePer: {d_seper}\\n', \n",
    "    f'SePer with one piece of information: {seper_piece1}, Î”SePer: {d_seper_piece1}\\n', \n",
    "    f'SePer with another piece of information: {seper_piece2}, Î”SePer: {d_seper_piece2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "searchr1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
